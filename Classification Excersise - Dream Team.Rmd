---
title: "Regression"
author: "Ran Dou, Mduduzi Langwenya, Kimo Li, Siyan Lin, Muhammad Furqan Shaikh, Tianyi Zhou"
date: "03/09/2019"
output: html_document
---
### Load the packages
```{r}
rm(list=ls())
library(tidyverse)
library(readr)
library(tidyverse)
library(forecast)
library(leaps)
library(pROC)
library(ggplot2)
library(reshape)
library(leaps)
library(corrplot)
library(knitr)
library(broom)
```

### I. Data cleaning and impution

##### Data importing
```{r, warning=FALSE, message=FALSE}
###import the raw diabetes data
diabetes <- read_csv("diabetes.csv")
###delete all the missing valuse
diabetes1 <- diabetes %>%
  filter( Glucose !=0 & BMI != 0 & BloodPressure != 0 & Insulin != 0 & SkinThickness != 0) %>%
  select(Glucose, Insulin, Outcome, BMI, SkinThickness )
```

##### Fill-in Zero Value
###### 1) Insulin
```{r,  message=FALSE}
### Insulin 
# stepwise for choosing models for Insulin 
insu.lm.null <- lm(Insulin~1, data = diabetes1)
insu.lm <- lm(Insulin~., data = diabetes1)
summary(insu.lm.null)
summary(insu.lm)
insu.lm.step_both <- step(insu.lm, direction = "both")
sum_both <- summary(insu.lm.step_both)
### create the model for imputing Insulin missing values
lm.data <- lm (Insulin ~ Glucose + BMI, data=diabetes1)
pred.1 <- predict (lm.data, diabetes1)
impute <-function(a, a.impute){
         ifelse(a$Insulin == 0, round(a.impute, 0), a$Insulin)
}
diabetes$newInsu <- impute(diabetes, pred.1)
```

###### 2) Skinthickness 
```{r}
### stepwise for choosing models for Insulin 
skin.lm.null <- lm(SkinThickness~1, data = diabetes1)
skin.lm <- lm(SkinThickness~., data = diabetes1)
skin.lm.step_both <- step(skin.lm, direction = "both")
sum_both_skin <- summary(skin.lm.step_both)
### create the model for imputing SkinThickness missing values
lm2.data <- lm(SkinThickness ~ BMI, data=diabetes1)
pred.2 <- predict (lm2.data, diabetes1)
impute <-function(a, a.impute){
  ifelse(a$SkinThickness == 0, round(a.impute, 0), a$SkinThickness)
}
diabetes$newSkin <- impute(diabetes, pred.2)

```

```{r}
################################ logistic regression part #############################
# CHANGE DATA TYPE
diabetes$Outcome <- as.factor(diabetes$Outcome)
diabetes$Pregnancies <- as.factor(diabetes$Pregnancies)

# divide data into train and test set
set.seed(1)
randOrder = order(runif(nrow(diabetes)))
train.df = subset(diabetes,randOrder < .8 * nrow(diabetes))
test.df = subset(diabetes,randOrder > .8 * nrow(diabetes))
```

##### correlation matrix

```{r, fig.width=6}
# plot the correlation matrix visual
train.df$Outcome <- as.numeric(train.df$Outcome)
train.df$Pregnancies <- as.numeric(train.df$Pregnancies)
cor <- cor(train.df)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```

```{r}
train.df$Outcome <- as.factor(train.df$Outcome)
train.df$Pregnancies <- as.factor(train.df$Pregnancies)
```

```{r}
### Forward Step-wise
# create model with no predictors for bottom of search range
dia.lm.null <- glm(Outcome~1, data = train.df, family = binomial)
dia.lm <- glm(Outcome~., data = train.df, family = binomial)
# use step() to run forward selection
dia.lm.step_for <- step(dia.lm.null,   
                    scope=list(lower=dia.lm.null, upper=dia.lm), direction = "forward")
sum_for <- summary(dia.lm.step_for) 

# Backward Step-wise
dia.lm.step_back <- step(dia.lm, direction = "backward")
sum_back <- summary(dia.lm.step_back) 

# Both Direction Step-wise
dia.lm.step_both <- step(dia.lm, direction = "both")
sum_both <- summary(dia.lm.step_both) 

# search
search <- regsubsets(Outcome ~ ., data = train.df, nbest = 1, 	nvmax = dim(train.df)[2], method = "exhaustive")
sum_sear <-summary(search)
sum_sear$which;
sum_sear$rsq;
sum_sear$adjr2;
sum_sear$Cp;

# comparison 
# same models with different methods
sum_for$coefficients
sum_back$coefficients
sum_both$coefficients

# best model with aic 536.4962
sum_for$aic

# Prediction on test data and accuracy test (73.1%)
tst_pred <- ifelse(predict(dia.lm.step_for, newdata = test.df, type = "response") > 0.5, "Yes", "No")
tst_tab <- table(predicted = tst_pred, actual = test.df$Outcome); sum(diag(tst_tab))/sum(tst_tab)
test_prob <- predict(dia.lm.step_for, newdata = test.df, type = "response")
test_roc <- roc(test.df$Outcome ~ test_prob, plot = TRUE, print.auc = TRUE) # 0.774
```

```{r, fig.width=3}
model1_data <- augment(dia.lm.step_for) %>% 
  mutate(index = 1:n()) %>%
  mutate(Outcome = ifelse(Outcome == "1", "0", "1"))
c <- ggplot(model1_data, aes(index, .std.resid, color = Outcome)) + 
  geom_point(stat = "identity") +
  labs(title = "Standardized Deviance Residuals", y = "Residual Std", x ="Residuals") +
  theme
c
```





